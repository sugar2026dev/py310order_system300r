# -*- coding: utf-8 -*-
import base64
import requests
import json
import re
import os
import time

# ================= é…ç½®åŒºåŸŸ =================
# ç™¾åº¦ API é…ç½®
API_KEY = "uvgL3QE0cyIDG5qowfnOR4JS"
SECRET_KEY = "BwP1QfCKrbFfSki7uqiaFh4EItu0ONHZ"

# å›¾ç‰‡è¾“å…¥ç›®å½•
INPUT_DIR = r"C:\02media\01sharefile\01order_info\0126\300\py310order_system300r\pic"

# ç»“æœè¾“å‡ºæ–‡ä»¶ (ä¿å­˜åœ¨è¾“å…¥ç›®å½•ä¸‹)
OUTPUT_FILE = os.path.join(INPUT_DIR, "ocr_result_all.txt")
# ===========================================

def get_access_token():
    """è·å–ç™¾åº¦ Access Token"""
    url = "https://aip.baidubce.com/oauth/2.0/token"
    params = {"grant_type": "client_credentials", "client_id": API_KEY, "client_secret": SECRET_KEY}
    try:
        response = requests.post(url, params=params)
        if response.status_code == 200:
            return response.json().get("access_token")
    except Exception as e:
        print(f"âŒ è·å– Token å¼‚å¸¸: {e}")
    return None

def get_baidu_ocr_result(image_path, token):
    """è°ƒç”¨ç™¾åº¦é«˜ç²¾åº¦OCR"""
    url = "https://aip.baidubce.com/rest/2.0/ocr/v1/accurate_basic"
    try:
        with open(image_path, 'rb') as fp:
            image_data = fp.read()
        image_base64 = base64.b64encode(image_data).decode('utf-8')
        headers = {'Content-Type': 'application/x-www-form-urlencoded'}
        data = {'image': image_base64, 'access_token': token}
        
        response = requests.post(url, headers=headers, data=data)
        return response.json()
    except Exception as e:
        return {"error_msg": str(e)}

def parse_data_logic(lines):
    """
    é€šç”¨çš„è§£æé€»è¾‘ (å°è¯•æå–å…³é”®ä¿¡æ¯)
    å³ä½¿æ˜¯ç©ºç™½å›¾æˆ–ä¸åŒç±»å‹çš„å›¾ï¼Œä¹Ÿä¼šè¿”å›ç©ºå­—å…¸
    """
    result = {
        'è®¢å•ç¼–å·': '', 'å•†å“åç§°': '', 'å•†å“è§„æ ¼': '', 'å•†å“ä»·æ ¼': '', 'å®ä»˜é‡‘é¢': '',
        'æ”¯ä»˜æ–¹å¼': '', 'ç‰©æµå…¬å¸': '', 'å¿«é€’å•å·': '', 'è®¢å•çŠ¶æ€': '', 'æ”¶ä»¶äºº': '',
        'è”ç³»æ–¹å¼': '', 'æ”¶è´§åœ°å€': '', 'åº—é“ºåç§°': '', 'ä¸‹å•æ—¶é—´': '', 'å‘è´§æ—¶é—´': ''
    }
    
    # è¾…åŠ©å˜é‡
    full_text = '\n'.join(lines)
    
    for i, line in enumerate(lines):
        line = line.strip()
        
        # æå–ç”µè¯/æ‰‹æœº (é€šç”¨åŒ¹é…)
        if not result['è”ç³»æ–¹å¼']:
            phone_match = re.search(r'(1[3-9]\d[\d\*]{6,8}\d{2,4})', line)
            if phone_match:
                result['è”ç³»æ–¹å¼'] = phone_match.group(1)
                # å°è¯•æå–åŒè¡Œçš„åå­—
                parts = line.split(result['è”ç³»æ–¹å¼'])
                if parts[0].strip():
                    name_candidate = parts[0].strip().replace('æ”¶è´§äºº', '').replace(':', '')
                    if len(name_candidate) < 10:
                        result['æ”¶ä»¶äºº'] = name_candidate

        # æå–åœ°å€ (é€šç”¨å…³é”®è¯)
        if not result['æ”¶è´§åœ°å€']:
            if any(k in line for k in ['çœ', 'å¸‚', 'åŒº', 'è¡—é“', 'è·¯', 'å·', 'å¤§å¦', 'å®¤']):
                if len(line) > 8: # ç®€å•è¿‡æ»¤çŸ­è¯
                    result['æ”¶è´§åœ°å€'] = line.replace('å±•å¼€', '').replace('âˆš', '').strip()

        # æå–é‡‘é¢
        if 'ï¿¥' in line or 'Â¥' in line:
            m = re.search(r'[ï¿¥Â¥]\s*(\d+\.?\d*)', line)
            if m:
                val = m.group(1)
                if 'å®ä»˜' in line: result['å®ä»˜é‡‘é¢'] = val
                elif not result['å•†å“ä»·æ ¼']: result['å•†å“ä»·æ ¼'] = val
        
        # æå–å•å· (æ•°å­—+å­—æ¯é•¿ä¸²)
        if 'å•å·' in line or 'ç¼–å·' in line:
            num = re.sub(r'[^\w-]', '', line.split('ï¼š')[-1].split(':')[-1])
            if len(num) > 8:
                if 'è®¢å•' in line: result['è®¢å•ç¼–å·'] = num
                elif 'å¿«é€’' in line or 'è¿å•' in line: result['å¿«é€’å•å·'] = num
        
        # æå–æ—¶é—´
        if re.search(r'\d{4}-\d{2}-\d{2}', line):
            t_str = re.search(r'\d{4}-\d{2}-\d{2}', line).group(0)
            full_t = re.search(r'\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2}', line)
            val = full_t.group(0) if full_t else t_str
            
            if 'ä¸‹å•' in line: result['ä¸‹å•æ—¶é—´'] = val
            elif 'å‘è´§' in line: result['å‘è´§æ—¶é—´'] = val
            
        # æå–çŠ¶æ€
        if line in ['å¾…å–ä»¶', 'å·²ç­¾æ”¶', 'è¿è¾“ä¸­', 'äº¤æ˜“æˆåŠŸ', 'å¾…å‘è´§', 'å¾…ä»˜æ¬¾']:
            result['è®¢å•çŠ¶æ€'] = line
            
    return result

def main():
    print(f"ğŸš€ å¼€å§‹æ‰¹é‡è¯†åˆ«ï¼Œç»“æœå°†å†™å…¥: {OUTPUT_FILE}")
    
    token = get_access_token()
    if not token:
        print("âŒ æ— æ³•è·å– Token")
        return

    # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
    files = [f for f in os.listdir(INPUT_DIR) if f.lower().endswith(('.jpg', '.png', '.jpeg', '.bmp'))]
    files.sort() # æŒ‰æ–‡ä»¶åæ’åº
    
    print(f"ğŸ“‚ æ‰¾åˆ° {len(files)} å¼ å›¾ç‰‡")
    
    # æ‰“å¼€æ–‡ä»¶å‡†å¤‡å†™å…¥
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f_out:
        f_out.write(f"ç™¾åº¦ OCR æ‰¹é‡è¯†åˆ«æŠ¥å‘Š\n")
        f_out.write(f"ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
        f_out.write("=" * 60 + "\n\n")

        for idx, filename in enumerate(files):
            file_path = os.path.join(INPUT_DIR, filename)
            print(f"[{idx+1}/{len(files)}] æ­£åœ¨è¯†åˆ«: {filename} ...")
            
            # 1. è°ƒç”¨ OCR
            raw_json = get_baidu_ocr_result(file_path, token)
            
            # 2. å‡†å¤‡å†™å…¥çš„æ•°æ®å—
            f_out.write(f"############################################################\n")
            f_out.write(f"FILE: {filename}\n")
            f_out.write(f"############################################################\n\n")
            
            if 'words_result' in raw_json:
                # æå–åŸå§‹æ–‡æœ¬è¡Œ
                raw_lines = [w['words'] for w in raw_json['words_result']]
                
                # å°è¯•è§£æ
                parsed_data = parse_data_logic(raw_lines)
                
                # --- å†™å…¥è§£æç»“æœ ---
                f_out.write("--- [1. è§£æå‡ºçš„å­—æ®µ (Extracted Fields)] ---\n")
                has_data = False
                for k, v in parsed_data.items():
                    if v: # åªæ˜¾ç¤ºæœ‰å€¼çš„å­—æ®µï¼Œæ›´æ¸…æ™°
                        f_out.write(f"{k:<10}: {v}\n")
                        has_data = True
                if not has_data:
                    f_out.write("(æœªæå–åˆ°æœ‰æ•ˆå­—æ®µ)\n")
                
                # --- å†™å…¥åŸå§‹æ–‡æœ¬ ---
                f_out.write("\n--- [2. åŸå§‹è¯†åˆ«æ–‡æœ¬ (Raw OCR Text)] ---\n")
                if not raw_lines:
                    f_out.write("(ç©ºç™½/æ— æ–‡å­—)\n")
                for i, line in enumerate(raw_lines):
                    f_out.write(f"{i+1:02d}: {line}\n")
                
                # --- å†™å…¥åŸå§‹ JSON (å¯é€‰ï¼Œæ”¾åœ¨æœ€å) ---
                f_out.write("\n--- [3. API åŸå§‹ JSON æ•°æ®] ---\n")
                f_out.write(json.dumps(raw_json, ensure_ascii=False) + "\n")
                
            else:
                f_out.write("âŒ è¯†åˆ«å¤±è´¥ / API é”™è¯¯:\n")
                f_out.write(json.dumps(raw_json, ensure_ascii=False) + "\n")
            
            f_out.write("\n\n") # æ–‡ä»¶é—´ç©ºè¡Œ
            f_out.flush()     # å®æ—¶å†™å…¥ç£ç›˜
            
            # é¿å…è§¦å‘ QPS é™åˆ¶
            time.sleep(0.5)

    print(f"\nâœ¨ å…¨éƒ¨å®Œæˆï¼ç»“æœå·²ä¿å­˜è‡³: {OUTPUT_FILE}")

if __name__ == '__main__':
    main()